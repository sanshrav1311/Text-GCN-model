{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de953446-40fa-4639-be3c-55ed3383b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920265c4-50d8-448e-86f3-51dbbe4a5c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5534c9-6eed-4932-a7d1-9242a6d50bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as pkl_file:\n",
    "        data = pickle.load(pkl_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1ae50c-e164-4451-bbbe-b0ace6666775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_pickle(filename, data):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(data, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c7c5046-55e0-4b92-a853-df3822c72bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gcn(nn.Module):\n",
    "    def __init__(self, X_size, A_hat, args): # X_size = num features\n",
    "        super(gcn, self).__init__()\n",
    "        self.A_hat = torch.tensor(A_hat, requires_grad=False).float()\n",
    "        self.weight = nn.parameter.Parameter(torch.FloatTensor(X_size, args[\"hidden_size_1\"]))\n",
    "        var = 2./(self.weight.size(1)+self.weight.size(0))\n",
    "        self.weight.data.normal_(0,var)\n",
    "        self.weight2 = nn.parameter.Parameter(torch.FloatTensor(args[\"hidden_size_1\"], args[\"hidden_size_2\"]))\n",
    "        var2 = 2./(self.weight2.size(1)+self.weight2.size(0))\n",
    "        self.weight2.data.normal_(0,var2)\n",
    "        self.bias = nn.parameter.Parameter(torch.FloatTensor(args[\"hidden_size_1\"]))\n",
    "        self.bias.data.normal_(0,var)\n",
    "        self.bias2 = nn.parameter.Parameter(torch.FloatTensor(args[\"hidden_size_2\"]))\n",
    "        self.bias2.data.normal_(0,var2)\n",
    "        self.fc1 = nn.Linear(args[\"hidden_size_2\"], args[\"num_classes\"])\n",
    "        \n",
    "    def forward(self, X): ### 2-layer GCN architecture\n",
    "        X = torch.mm(X, self.weight)\n",
    "        X = (X + self.bias)\n",
    "        X = F.relu(torch.mm(self.A_hat, X))\n",
    "        X = torch.mm(X, self.weight2)\n",
    "        X = (X + self.bias2)\n",
    "        X = F.relu(torch.mm(self.A_hat, X))\n",
    "        return self.fc1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b511a454-0f04-4ff3-9eb7-2ed55e3d1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_results(columnName, args=None):\n",
    "    #Load data here\n",
    "    \n",
    "    ### Loads graph data\n",
    "    G_path = \"text_graph_%s.pkl\" % columnName\n",
    "    G = load_pickle(G_path)\n",
    "    A = nx.to_numpy_array(G, weight=\"weight\"); A = A + np.eye(G.number_of_nodes())\n",
    "    degrees = []\n",
    "    for d in G.degree(weight=None):\n",
    "        if d == 0:\n",
    "            degrees.append(0)\n",
    "        else:\n",
    "            degrees.append(d[1]**(-0.5))\n",
    "    degrees = np.diag(degrees)\n",
    "    X = np.eye(G.number_of_nodes()) # Features are just identity matrix\n",
    "    A_hat = degrees@A@degrees\n",
    "    f = X # (n X n) X (n X n) x (n X n) X (n X n) input of net\n",
    "    f = torch.from_numpy(f).float()\n",
    "    print(\"A_hat, f and X generated for testing\") #marker\n",
    "    ### Loads labels\n",
    "    test_idxs = load_pickle(\"test_idxs.pkl\")\n",
    "    labels_selected = load_pickle(\"labels_selected.pkl\")\n",
    "    labels_not_selected = load_pickle(\"labels_not_selected.pkl\")\n",
    "    \n",
    "    ### Loads best model ###\n",
    "    net = gcn(X.shape[1], A_hat, args)\n",
    "    net_model_state = load_pickle(\"net_model_state.pkl\")\n",
    "    net.load_state_dict(net_model_state)\n",
    "    print(\"model revived for testing\") #marker\n",
    "    ### Inference\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_labels = net(f)\n",
    "    save_as_pickle(\"pred_labels_%s.pkl\" % columnName , pred_labels)\n",
    "\n",
    "    print(\"pred_labels saved\") #marker\n",
    "#     fig = plt.figure(figsize=(25,25))\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     sb.heatmap(c_m, annot=False)\n",
    "#     ax.set_title(\"Confusion Matrix\", fontsize=20)\n",
    "#     ax.set_xlabel(\"Actual class\", fontsize=17)\n",
    "#     ax.set_ylabel(\"Predicted\", fontsize=17)\n",
    "#     plt.savefig(\"confusion_matrix.png\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae968a5-799d-4ef2-952e-c1ae8f9967b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(columnName):\n",
    "    \"\"\"Loads dataset and graph if exists, else create and process them from raw data\n",
    "    Returns --->\n",
    "    f: torch tensor input of GCN (Identity matrix)\n",
    "    X: input of GCN (Identity matrix)\n",
    "    A_hat: transformed adjacency matrix A\n",
    "    selected: indexes of selected labelled nodes for training\n",
    "    test_idxs: indexes of not-selected nodes for inference/testing\n",
    "    labels_selected: labels of selected labelled nodes for training\n",
    "    labels_not_selected: labels of not-selected labelled nodes for inference/testing\n",
    "    \"\"\"\n",
    "    G_path = \"text_graph_%s.pkl\" % columnName\n",
    "    print(G_path)\n",
    "    G = load_pickle(G_path)\n",
    "    \n",
    "    A = nx.to_numpy_array(G, weight=\"weight\"); A = A + np.eye(G.number_of_nodes())\n",
    "    degrees = []\n",
    "    for d in G.degree(weight=None):\n",
    "        if d == 0:\n",
    "            degrees.append(0)\n",
    "        else:\n",
    "            degrees.append(d[1]**(-0.5))\n",
    "    degrees = np.diag(degrees)\n",
    "    X = np.eye(G.number_of_nodes()) # Features are just identity matrix\n",
    "    A_hat = degrees@A@degrees\n",
    "    f = X # (n X n) X (n X n) x (n X n) X (n X n) input of net\n",
    "    print(\"A_hat, f and X generated\") #marker\n",
    "    selected = load_pickle(\"selected.pkl\")\n",
    "    labels_selected = load_pickle(\"labels_selected.pkl\")\n",
    "    labels_not_selected = load_pickle(\"labels_not_selected.pkl\")\n",
    "    \n",
    "    f_selected = f[selected]; f_selected = torch.from_numpy(f_selected).float()\n",
    "    \n",
    "    f_not_selected = f[test_idxs]; f_not_selected = torch.from_numpy(f_not_selected).float()\n",
    "    \n",
    "    f = torch.from_numpy(f).float()\n",
    "    return f, X, A_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e79c386e-fe29-4c04-91fe-b39bcaa98f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(column):\n",
    "    f, X, A_hat = load_datasets(column)\n",
    "    net = gcn(X.shape[1], A_hat, args)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=args[\"lr\"])\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,2000,3000,4000,5000,6000], gamma=0.77)\n",
    "\n",
    "    start_epoch, best_pred, checkpoint = 0, 0, None\n",
    "    losses_per_epoch, accuracy_per_epoch = [], []\n",
    "    print(\"Start training\") #marker\n",
    "    net.train()\n",
    "    evaluation_trained = []\n",
    "    for e in range(start_epoch, args[\"num_epochs\"]):\n",
    "        print(\"epoch_no. %d\" % e) #marker\n",
    "        optimizer.zero_grad()\n",
    "        output = net(f)\n",
    "        loss = criterion(output[selected], torch.tensor(labels_selected).long() -1)\n",
    "        # losses_per_epoch.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    save_as_pickle(\"net_model_state.pkl\" % net.state_dict())\n",
    "    print(\"Evaluating model results\") #marker\n",
    "    evaluate_model_results(column, args=args)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57895b0-1945-49c9-9bb7-abe6253f87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"hidden_size_1\": 330,\n",
    "        \"hidden_size_2\": 130,\n",
    "        \"num_classes\": 66,\n",
    "        \"test_ratio\": 0.1,\n",
    "        \"num_epochs\": 3300,\n",
    "        \"lr\": 0.011,\n",
    "        \"model_no\": 0\n",
    "}\n",
    "save_as_pickle(\"args.pkl\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3a02613-eb20-43d9-8583-bfdd60246220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"PubMedDataClean.csv\", index_col=False)\n",
    "### stratified test samples\n",
    "test_idxs = []\n",
    "dum = df_data[\"DocID\"]\n",
    "\n",
    "test_idxs.extend(list(np.random.choice(dum.index, size=round(args[\"test_ratio\"]*len(dum)), replace=False)))\n",
    "save_as_pickle(\"test_idxs.pkl\", test_idxs)\n",
    "# select only certain labelled nodes for semi-supervised GCN\n",
    "selected = []\n",
    "for i in range(len(df_data)):\n",
    "    if i not in test_idxs:\n",
    "        selected.append(i)\n",
    "save_as_pickle(\"selected.pkl\", selected)\n",
    "\n",
    "labels_selected = [l for idx, l in enumerate(df_data[\"DocID\"]) if idx in selected]\n",
    "labels_not_selected = [l for idx, l in enumerate(df_data[\"DocID\"]) if idx not in selected]\n",
    "save_as_pickle(\"labels_selected.pkl\", labels_selected)\n",
    "save_as_pickle(\"labels_not_selected.pkl\", labels_not_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df18ded-d87e-44ae-98c0-7aef8e64ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"TITLE_CLEAN\", \"KEYWORDS_CLEAN\", \"ABSTRACT_CLEAN\"]:\n",
    "    predict_labels(column = column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbaeb5-419a-4fc8-8237-04601eee22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_majority = []\n",
    "\n",
    "pred_labels_TITLE_CLEAN = load_pickle(\"pred_labels_TITLE_CLEAN.pkl\")\n",
    "pred_labels_KEYWORDS_CLEAN = load_pickle(\"pred_labels_KEYWORDS_CLEAN.pkl\")\n",
    "pred_labels_ABSTRACT_CLEAN = load_pickle(\"pred_labels_ABSTRACT_CLEAN.pkl\")\n",
    "\n",
    "for i in range(len(pred_labels_TITLE_CLEAN)):\n",
    "    pred_labels_majority[i] = int((pred_labels_TITLE_CLEAN[i] + pred_labels_KEYWORDS_CLEAN[i] + pred_labels_ABSTRACT_CLEAN[i]) / 2)\n",
    "\n",
    "c_m = confusion_matrix([(e-1) for e in labels_not_selected], list(pred_labels_majority[test_idxs].max(1)[1].numpy()))\n",
    "save_as_pickle(\"confusion_matrix.pkl\", c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "693b89e3-7e48-45f1-a4f7-7ea3f3a354fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE_CLEAN\n"
     ]
    }
   ],
   "source": [
    "print(columnList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c9bbf-75d2-4a8f-be6e-80bd8724fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_graph_TITLE_CLEAN.pkl\n"
     ]
    }
   ],
   "source": [
    "predict_labels(column = columnList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16c18e-746b-42c4-8a5f-b289571a81f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
